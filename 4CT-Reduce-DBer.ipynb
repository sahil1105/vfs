{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import sqlite3\n",
    "import os\n",
    "import sys\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partition(l, p):\n",
    "     return reduce(lambda x, y: x[not p(y)].append(y) or x, l, ([], []))\n",
    "\n",
    "def get_numbers_in_line(l):\n",
    "    fmt = r'\\d+'\n",
    "    return list(map(int, re.findall(fmt, l)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReduceLogParser:\n",
    "\n",
    "    DEFAULT_REDUCE_LOG_FILE = 'reduce-stdout.txt'\n",
    "\n",
    "    @staticmethod\n",
    "    def get_segments(lines):\n",
    "        segments = []\n",
    "        curr_segment = []\n",
    "\n",
    "        collect = False\n",
    "\n",
    "        for i, l in enumerate(lines):\n",
    "\n",
    "            if re.match(r'^\\-+$', l) is not None:\n",
    "                if len(curr_segment) > 0:\n",
    "                    segments.append(curr_segment)\n",
    "                    curr_segment = []\n",
    "                collect = False\n",
    "            elif re.match(r'^Configuration \\d+$', l) is not None:\n",
    "                if len(curr_segment) > 0:\n",
    "                    segments.append(curr_segment)\n",
    "                    curr_segment = []\n",
    "                collect = False\n",
    "            elif re.match(r'^This has ring-size', l) is not None:\n",
    "                if len(curr_segment) > 0:\n",
    "                    segments.append(curr_segment)\n",
    "                    curr_segment = []\n",
    "                curr_segment.append(l)\n",
    "                collect = True\n",
    "            elif re.match(r'^\\*\\*', l) is not None:\n",
    "                if len(curr_segment) > 0:\n",
    "                    curr_segment.append(l)\n",
    "                    segments.append(curr_segment)\n",
    "                    curr_segment = []\n",
    "                elif len(segments) > 0:\n",
    "                    segments[-1].append(l)\n",
    "                collect = False\n",
    "            elif re.match(r'^Configuration \\d+: maximum', l) is not None:\n",
    "                if len(curr_segment) > 0:\n",
    "                    curr_segment.append(l)\n",
    "                    segments.append(curr_segment)\n",
    "                    curr_segment = []\n",
    "                elif len(segments) > 0:\n",
    "                    segments[-1].append(l)\n",
    "                collect = False\n",
    "                curr_segment = []\n",
    "            elif re.match(r'^Configuration \\d+: augment depth 8 >= 8 \\(would crash if not patched\\)$', l) is not None:\n",
    "                if len(curr_segment) > 0:\n",
    "                    curr_segment.append(l)\n",
    "                    segments.append(curr_segment)\n",
    "                    curr_segment = []\n",
    "                elif len(segments) > 0:\n",
    "                    segments[-1].append(l)\n",
    "                collect = False\n",
    "                curr_segment = []\n",
    "            elif re.match(r'^Reducibility of', l) is not None:\n",
    "                collect = False\n",
    "                break\n",
    "            elif collect and len(l.strip()) > 0:\n",
    "                curr_segment.append(l)\n",
    "\n",
    "        if len(curr_segment) > 0:\n",
    "            segments.append(curr_segment)\n",
    "\n",
    "        return segments\n",
    "\n",
    "    @staticmethod\n",
    "    def parse_config_verification(config_lines):\n",
    "        config_lines = list(filter(lambda x: len(x.strip()) > 0, config_lines))\n",
    "\n",
    "        augment_depth = None\n",
    "        if re.match(r'^Configuration \\d+: maximum', config_lines[-1]):\n",
    "            [_, augment_depth] = get_numbers_in_line(config_lines[-1])\n",
    "            config_lines = config_lines[:-1]\n",
    "        elif re.match(r'^Configuration \\d+: augment depth 8 >= 8 \\(would crash if not patched\\)$', config_lines[-1]):\n",
    "            augment_depth = 8\n",
    "            config_lines = config_lines[:-1]\n",
    "\n",
    "        l1, l2, l3, _, _, *l4, l5 = config_lines\n",
    "\n",
    "        l4, l4_r = partition(l4, lambda l: re.match(r'^\\*\\*', l) is None)\n",
    "        l5 = l4_r + [l5]\n",
    "        l5 = \"\\n\".join(l5)\n",
    "\n",
    "        [ring_size, n_col] = get_numbers_in_line(l1)\n",
    "        [sima] = get_numbers_in_line(l2)\n",
    "        [ncol_x] = get_numbers_in_line(l3)\n",
    "\n",
    "        iter_log = list(map(get_numbers_in_line, l4))\n",
    "        ncol_i_log = [x[0] for x in iter_log]\n",
    "        sima_i_log = [x[1] for x in iter_log[:-1]]\n",
    "        outcome = l5\n",
    "\n",
    "        return ring_size, n_col, sima, ncol_x, ncol_i_log, sima_i_log, outcome, augment_depth\n",
    "\n",
    "    @staticmethod\n",
    "    def parse_reduce_log(exp_dir, log_file=DEFAULT_REDUCE_LOG_FILE):\n",
    "        fname = os.path.join(exp_dir, log_file)\n",
    "        if not os.path.isfile(fname):\n",
    "            return None\n",
    "        lines = []\n",
    "        with open(fname, 'r') as f:\n",
    "            lines = list(map(str.strip, f.readlines()))\n",
    "        segments = ReduceLogParser.get_segments(lines)\n",
    "        return list(map(ReduceLogParser.parse_config_verification, segments))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigParser:\n",
    "    DEFAULT_CONFIG_FILE = 'config.conf'\n",
    "\n",
    "    @staticmethod\n",
    "    def get_config_file_segments(lines):\n",
    "        segments = []\n",
    "        curr_segment = []\n",
    "        for l in lines:\n",
    "            if l == '':\n",
    "                segments.append(curr_segment)\n",
    "                curr_segment = []\n",
    "            else:\n",
    "                curr_segment.append(l)\n",
    "        return segments\n",
    "\n",
    "    @staticmethod\n",
    "    def parse_config(lines):\n",
    "        ID = lines[0]\n",
    "        [N, R, A, B] = list(map(int, lines[1].split()))\n",
    "        RC, *edges_in_x = list(map(int, lines[2].split()))\n",
    "        if len(edges_in_x) != 2 * RC:\n",
    "            print(\"Edges in X list not as expected. Expected {} numbers, got {}.\".format(2 * RC, len(edges_in_x)))\n",
    "\n",
    "        adjacency_list = []\n",
    "        for v_id, v_desc in enumerate(lines[3:N + 3]):\n",
    "            vertex_id, vertex_num_neighbors, *vertex_adjancency_list = list(map(int, v_desc.split()))\n",
    "            if vertex_id != (v_id + 1):\n",
    "                print(\"Vertex ID not as expected. Expected {}, got {}.\".format(v_id + 1, vertex_id))\n",
    "            if vertex_num_neighbors != len(vertex_adjancency_list):\n",
    "                print(\"Adjacency list not as expected. Expected {} elements, got {}.\"\n",
    "                      .format(len(vertex_adjancency_list), vertex_num_neighbors))\n",
    "            adjacency_list.append(vertex_adjancency_list)\n",
    "\n",
    "        positions = []\n",
    "        for l in lines[N + 3:]:\n",
    "            coords = list(map(int, l.split()))\n",
    "            positions.extend(coords)\n",
    "\n",
    "        if len(positions) != N:\n",
    "            print(\"Number of positions parsed not as expected. Expected {}, got {}.\".format(N, len(positions)))\n",
    "\n",
    "        return ID, N, R, A, B, RC, adjacency_list, positions, edges_in_x\n",
    "\n",
    "    @staticmethod\n",
    "    def serialize_adjacency_list(adj_list):\n",
    "        return \";\".join(list(map(lambda x: \",\".join(map(str, x)), adj_list)))\n",
    "\n",
    "    @staticmethod\n",
    "    def deserialize_adjacency_list(serialized_adj_list):\n",
    "        return list(map(lambda x: list(map(int, x.split(','))), serialized_adj_list.split(\";\")))\n",
    "\n",
    "    @staticmethod\n",
    "    def serialize_vertex_positions(vertex_positions):\n",
    "        return \",\".join(map(str, vertex_positions))\n",
    "\n",
    "    @staticmethod\n",
    "    def deserialize_vertex_positions(serialized_vertex_positions):\n",
    "        return list(map(int, serialized_vertex_positions.split(',')))\n",
    "\n",
    "    @staticmethod\n",
    "    def serialize_edges_in_x(edges_in_x):\n",
    "        pairs = [\"{},{}\".format(str(edges_in_x[2 * i]), str(edges_in_x[2 * i + 1])) for i in\n",
    "                 range(len(edges_in_x) // 2)]\n",
    "        return \";\".join(pairs)\n",
    "\n",
    "    @staticmethod\n",
    "    def deserialize_edges_in_x(serialized_edges_in_x):\n",
    "        if serialized_edges_in_x == '':\n",
    "            return []\n",
    "        pairs = serialized_edges_in_x.split(';')\n",
    "        edges_in_x = []\n",
    "        for pair in pairs:\n",
    "            pair = pair.split(',')\n",
    "            pair = list(map(int, pair))\n",
    "            edges_in_x.extend(pair)\n",
    "        return edges_in_x\n",
    "\n",
    "    @staticmethod\n",
    "    def parse_configs_from_file(fname):\n",
    "        with open(fname, 'r')  as f:\n",
    "            lines = list(map(str.strip, f.readlines()))\n",
    "        config_file_segments = ConfigParser.get_config_file_segments(lines)\n",
    "        config_descs = list(map(ConfigParser.parse_config, config_file_segments))\n",
    "        config_descs = list(map(lambda x:\n",
    "                                (x[0], x[1], x[2], x[3], x[4], x[5],\n",
    "                                 ConfigParser.serialize_adjacency_list(x[6]),\n",
    "                                 ConfigParser.serialize_vertex_positions(x[7]),\n",
    "                                 ConfigParser.serialize_edges_in_x(x[8])),\n",
    "                                config_descs))\n",
    "        return config_descs\n",
    "\n",
    "    @staticmethod\n",
    "    def parse_configs_from_exp_dir(exp_dir, config_file=DEFAULT_CONFIG_FILE):\n",
    "        fname = os.path.join(exp_dir, config_file)\n",
    "        if not os.path.isfile(fname):\n",
    "            return []\n",
    "        return ConfigParser.parse_configs_from_file(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MetaDataParser:\n",
    "\n",
    "    DEFAULT_COMPILER_INFO_FILE = 'cc.txt'\n",
    "    DEFAULT_COMPILE_TIME_SYSTEM_INFO_FILE = 'compile_os.txt'\n",
    "    DEFAULT_RUN_TIME_SYSTEM_INFO_FILE = 'runtime_os.txt'\n",
    "    DEFAULT_SYSTEM_INFO_FILE = 'os.txt'\n",
    "    DEFAULT_VERSION_NOTES_FILE = 'version_notes.txt'\n",
    "\n",
    "    @staticmethod\n",
    "    def parse_file(fname):\n",
    "        if os.path.isfile(fname):\n",
    "            with open(fname, 'r') as f:\n",
    "                lines = map(str.strip, f.readlines())\n",
    "                lines = list(filter(lambda x: len(x) > 0, lines))\n",
    "            return \"\\n\".join(lines)\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    @staticmethod\n",
    "    def parse_compile_time_system_details(exp_dir):\n",
    "        t = MetaDataParser.parse_file(os.path.join(exp_dir, MetaDataParser.DEFAULT_COMPILE_TIME_SYSTEM_INFO_FILE))\n",
    "        if t is None:\n",
    "            t = MetaDataParser.parse_file(os.path.join(exp_dir, MetaDataParser.DEFAULT_SYSTEM_INFO_FILE))\n",
    "        return t\n",
    "\n",
    "    @staticmethod\n",
    "    def parse_runtime_system_details(exp_dir):\n",
    "        t = MetaDataParser.parse_file(os.path.join(exp_dir, MetaDataParser.DEFAULT_RUN_TIME_SYSTEM_INFO_FILE))\n",
    "        if t is None:\n",
    "            t = MetaDataParser.parse_file(os.path.join(exp_dir, MetaDataParser.DEFAULT_SYSTEM_INFO_FILE))\n",
    "        return t\n",
    "\n",
    "    @staticmethod\n",
    "    def parse_compiler_details(exp_dir):\n",
    "        return MetaDataParser.parse_file(os.path.join(exp_dir, MetaDataParser.DEFAULT_COMPILER_INFO_FILE))\n",
    "\n",
    "    @staticmethod\n",
    "    def parse_version_notes(exp_dir):\n",
    "        return MetaDataParser.parse_file(os.path.join(exp_dir, MetaDataParser.DEFAULT_VERSION_NOTES_FILE))\n",
    "\n",
    "    @staticmethod\n",
    "    def extract_run_info(exp_dir):\n",
    "\n",
    "        return {\n",
    "            'compile_time_sys': MetaDataParser.parse_compile_time_system_details(exp_dir),\n",
    "            'run_time_sys': MetaDataParser.parse_runtime_system_details(exp_dir),\n",
    "            'compiler': MetaDataParser.parse_compiler_details(exp_dir),\n",
    "            'notes': MetaDataParser.parse_version_notes(exp_dir),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SqliteHandler:\n",
    "\n",
    "    create_reduceLog_table_sql = \"\"\" CREATE TABLE IF NOT EXISTS reduceLog (\n",
    "                                                runID integer NOT NULL,\n",
    "                                                configIndex integer NOT NULL,\n",
    "                                                ringSize integer NOT NULL,\n",
    "                                                ncol integer NOT NULL,\n",
    "                                                sima integer NOT NULL,\n",
    "                                                ncolx integer NOT NULL,\n",
    "                                                outcome text,\n",
    "                                                maxAugmentDepth integer,\n",
    "                                                PRIMARY KEY (runID, configIndex)\n",
    "                                            );\n",
    "                                 \"\"\"\n",
    "\n",
    "    create_run_table_sql = \"\"\" CREATE TABLE IF NOT EXISTS run (\n",
    "                                            runID integer NOT NULL,\n",
    "                                            compile_time_sys text,\n",
    "                                            run_time_sys text,\n",
    "                                            compiler text,\n",
    "                                            notes text,\n",
    "                                            PRIMARY KEY (runID)\n",
    "                                        ); \n",
    "                                \"\"\"\n",
    "\n",
    "    create_progress_table_sql = \"\"\" CREATE TABLE IF NOT EXISTS progress (\n",
    "                                            runID integer NOT NULL,\n",
    "                                            configIndex integer NOT NULL,\n",
    "                                            round integer NOT NULL,\n",
    "                                            ncol_i integer,\n",
    "                                            sima_i integer,\n",
    "                                            PRIMARY KEY (runID, configIndex, round)\n",
    "                                        ); \n",
    "                                 \"\"\"\n",
    "\n",
    "    create_config_table_sql = \"\"\" CREATE TABLE IF NOT EXISTS config (\n",
    "                                            configIndex INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "                                            configID text NOT NULL,\n",
    "                                            numVertices integer NOT NULL,\n",
    "                                            ringSize integer NOT NULL,\n",
    "                                            ncolx integer NOT NULL,\n",
    "                                            ncolxp integer NOT NULL,\n",
    "                                            numEdgesX integer NOT NULL,\n",
    "                                            adjacencyList text NOT NULL,\n",
    "                                            vertexCoords text NOT NULL,\n",
    "                                            edgesInX text NOT NULL,\n",
    "                                            configSet text,\n",
    "                                            UNIQUE (configID, numVertices, ringSize, ncolx, ncolxp, numEdgesX, adjacencyList, vertexCoords, edgesInX)\n",
    "                                        ); \n",
    "                                 \"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def create_connection(db_file):\n",
    "        \"\"\" create a database connection to the SQLite database\n",
    "            specified by db_file\n",
    "        :param db_file: database file\n",
    "        :return: Connection object or None\n",
    "        \"\"\"\n",
    "        conn = None\n",
    "        try:\n",
    "            conn = sqlite3.connect(db_file)\n",
    "            return conn\n",
    "        except sqlite3.Error as e:\n",
    "            print(e)\n",
    "\n",
    "        return conn\n",
    "\n",
    "    @staticmethod\n",
    "    def create_table(conn, create_table_sql):\n",
    "        \"\"\" create a table from the create_table_sql statement\n",
    "        :param conn: Connection object\n",
    "        :param create_table_sql: a CREATE TABLE statement\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        try:\n",
    "            c = conn.cursor()\n",
    "            c.execute(create_table_sql)\n",
    "        except sqlite3.Error as e:\n",
    "            print(e)\n",
    "\n",
    "    @staticmethod\n",
    "    def get_max_run_id_from_table(table_name, conn):\n",
    "        max_run_id_query = \"SELECT MAX(runID) FROM {}\".format(table_name)\n",
    "        try:\n",
    "            c = conn.cursor()\n",
    "            c = c.execute(max_run_id_query)\n",
    "            v = c.fetchall()[0][0]\n",
    "            if v:\n",
    "                return v\n",
    "            else:\n",
    "                return 0\n",
    "        except sqlite3.Error as e:\n",
    "            print(e)\n",
    "\n",
    "    @staticmethod\n",
    "    def get_next_run_id(conn):\n",
    "        return max([SqliteHandler.get_max_run_id_from_table(table_name, conn) for table_name in ['reduceLog', 'run', 'progress']]) + 1\n",
    "\n",
    "    @staticmethod\n",
    "    def insert_in_table(conn, table_name, key_value_pairs):\n",
    "\n",
    "        kv_s = key_value_pairs.items()\n",
    "        keys = [x[0] for x in kv_s]\n",
    "        values = [x[1] for x in kv_s]\n",
    "        insertion_sql_query = \"\"\" INSERT INTO {0}({1})\n",
    "                                  VALUES({2})\n",
    "                              \"\"\".format(table_name, \",\".join(keys), \",\".join(['?' for _ in values]))\n",
    "        cur = conn.cursor()\n",
    "        cur.execute(insertion_sql_query, values)\n",
    "        return cur.lastrowid\n",
    "\n",
    "    @staticmethod\n",
    "    def get_config_index(conn, config_desc):\n",
    "\n",
    "        config_exists_check_sql = \"\"\" SELECT configIndex FROM config WHERE\n",
    "                                      configID = ? AND\n",
    "                                      numVertices = ? AND\n",
    "                                      ringSize = ? AND\n",
    "                                      ncolx = ? AND\n",
    "                                      ncolxp = ? AND\n",
    "                                      numEdgesX = ? AND\n",
    "                                      adjacencyList = ? AND\n",
    "                                      vertexCoords = ? AND\n",
    "                                      edgesInX = ?\n",
    "                                  \"\"\"\n",
    "\n",
    "        try:\n",
    "            c = conn.cursor()\n",
    "            c = c.execute(config_exists_check_sql, config_desc)\n",
    "            v = c.fetchall()\n",
    "            if len(v) > 0:\n",
    "                return v[0][0]\n",
    "            else:\n",
    "                return None\n",
    "        except sqlite3.Error as e:\n",
    "            print(e)\n",
    "\n",
    "    @staticmethod\n",
    "    def config_desc_to_kv_s(config_desc):\n",
    "        configID, numVertices, ringSize, ncolx, ncolxp, numEdgesX, adjacencyList, vertexCoords, edgesInX = config_desc\n",
    "        kv_s = {\n",
    "            'configID': configID,\n",
    "            'numVertices': numVertices,\n",
    "            'ringSize': ringSize,\n",
    "            'ncolx': ncolx,\n",
    "            'ncolxp': ncolxp,\n",
    "            'numEdgesX': numEdgesX,\n",
    "            'adjacencyList': adjacencyList,\n",
    "            'vertexCoords': vertexCoords,\n",
    "            'edgesInX': edgesInX,\n",
    "        }\n",
    "        return kv_s\n",
    "\n",
    "    @staticmethod\n",
    "    def insert_config_into_table(conn, config_desc, config_set=None):\n",
    "\n",
    "        kv_s = SqliteHandler.config_desc_to_kv_s(config_desc)\n",
    "        configIndex = None\n",
    "        if config_set is not None:\n",
    "            kv_s['configSet'] = config_set\n",
    "        try:\n",
    "            configIndex = SqliteHandler.insert_in_table(conn, 'config', kv_s)\n",
    "            return configIndex\n",
    "        except sqlite3.Error as e:\n",
    "            if \"UNIQUE constraint failed\" in e.args[0]:\n",
    "                configIndex = SqliteHandler.get_config_index(conn, config_desc)\n",
    "                return configIndex\n",
    "            else:\n",
    "                print(e)\n",
    "\n",
    "    @staticmethod\n",
    "    def insert_and_get_config_indices(conn, config_descs, config_set=None):\n",
    "        return list(map(lambda x: SqliteHandler.insert_config_into_table(conn, x, config_set), config_descs))\n",
    "\n",
    "    @staticmethod\n",
    "    def insert_into_reduceLog_table(conn, db, run_id):\n",
    "\n",
    "        for i, (configIndex, ring_size, n_col, sima, ncol_x, _, _, outcome, augment_depth) in enumerate(db):\n",
    "            kv_s = {'runID': run_id,\n",
    "                    'configIndex': configIndex,\n",
    "                    'ringSize': ring_size,\n",
    "                    'ncol': n_col,\n",
    "                    'sima': sima,\n",
    "                    'ncolx': ncol_x,\n",
    "                    'outcome': outcome,\n",
    "                    'maxAugmentDepth': augment_depth,\n",
    "                    }\n",
    "            SqliteHandler.insert_in_table(conn, 'reduceLog', kv_s)\n",
    "\n",
    "    @staticmethod\n",
    "    def insert_into_progress_table(conn, db, run_id):\n",
    "\n",
    "        for i, (configIndex, _, _, _, _, ncol_iter_log, sima_iter_log, _, _) in enumerate(db):\n",
    "\n",
    "            n = len(ncol_iter_log)\n",
    "            for j in range(n - 1):\n",
    "                kv_s = {\n",
    "                    'runID': run_id,\n",
    "                    'configIndex': configIndex,\n",
    "                    'round': j + 1,\n",
    "                    'ncol_i': ncol_iter_log[j],\n",
    "                    'sima_i': sima_iter_log[j],\n",
    "                }\n",
    "\n",
    "                SqliteHandler.insert_in_table(conn, 'progress', kv_s)\n",
    "\n",
    "            kv_s = {\n",
    "                'runID': run_id,\n",
    "                'configIndex': configIndex,\n",
    "                'round': n,\n",
    "                'ncol_i': ncol_iter_log[n - 1],\n",
    "            }\n",
    "\n",
    "            SqliteHandler.insert_in_table(conn, 'progress', kv_s)\n",
    "\n",
    "    @staticmethod\n",
    "    def insert_into_run_table(conn, run_info, run_id):\n",
    "\n",
    "        run_info = run_info.copy()\n",
    "        run_info['runID'] = run_id\n",
    "        SqliteHandler.insert_in_table(conn, 'run', run_info)\n",
    "\n",
    "    @staticmethod\n",
    "    def setup_sqlite_db(db_name):\n",
    "        conn = SqliteHandler.create_connection(db_name)\n",
    "        SqliteHandler.create_table(conn, SqliteHandler.create_config_table_sql)\n",
    "        SqliteHandler.create_table(conn, SqliteHandler.create_reduceLog_table_sql)\n",
    "        SqliteHandler.create_table(conn, SqliteHandler.create_run_table_sql)\n",
    "        SqliteHandler.create_table(conn, SqliteHandler.create_progress_table_sql)\n",
    "        conn.commit()\n",
    "        return conn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_config_indices_to_reduce_log(reduce_log, config_indices):\n",
    "    return list(map(lambda x: (x[0],*x[1]), zip(config_indices, reduce_log)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_config_table(db_name):\n",
    "    file_configSet_map = {\n",
    "        os.path.join('config-files', 'JPS-2822.conf'): 'JPS',\n",
    "        os.path.join('config-files', 'RSST-unavoidable.conf'): 'RSST',\n",
    "    }\n",
    "    conn = SqliteHandler.setup_sqlite_db(db_name)\n",
    "    for config_f, config_set in file_configSet_map.items():\n",
    "        config_descs = ConfigParser.parse_configs_from_file(config_f)\n",
    "        config_indices = SqliteHandler.insert_and_get_config_indices(conn, config_descs, config_set)\n",
    "    conn.commit()\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_exp_dir(exp_dir, db_name, config_set=None):\n",
    "    conn = SqliteHandler.setup_sqlite_db(db_name)\n",
    "    \n",
    "    config_descs = ConfigParser.parse_configs_from_exp_dir(exp_dir)\n",
    "    config_indices = SqliteHandler.insert_and_get_config_indices(conn, config_descs, config_set)\n",
    "    conn.commit()\n",
    "    \n",
    "    log_db = ReduceLogParser.parse_reduce_log(exp_dir)\n",
    "    log_db = add_config_indices_to_reduce_log(log_db, config_indices)\n",
    "    run_info = MetaDataParser.extract_run_info(exp_dir)\n",
    "    \n",
    "    run_id = SqliteHandler.get_next_run_id(conn)\n",
    "    SqliteHandler.insert_into_reduceLog_table(conn, log_db, run_id)\n",
    "    SqliteHandler.insert_into_progress_table(conn, log_db, run_id)\n",
    "    SqliteHandler.insert_into_run_table(conn, run_info, run_id)\n",
    "    \n",
    "    conn.commit()\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_file = '4ct_db.db'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "initialize_config_table(db_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_dir_to_parse = 'Sahil-MBP-patched-all-JPS-configs'\n",
    "process_exp_dir(exp_dir_to_parse, db_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_dir_to_parse = 'Sahil-MBP-patched-all-RSST-configs'\n",
    "process_exp_dir(exp_dir_to_parse, db_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_dir_to_parse = '../vfs-robert/system76/'\n",
    "process_exp_dir(exp_dir_to_parse, db_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_dir_to_parse = 'Sahil-MBP-unpatched-all-JPS-configs'\n",
    "process_exp_dir(exp_dir_to_parse, db_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_dir_to_parse = 'Sahil-MBP-unpatched-all-RSST-configs'\n",
    "process_exp_dir(exp_dir_to_parse, db_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
